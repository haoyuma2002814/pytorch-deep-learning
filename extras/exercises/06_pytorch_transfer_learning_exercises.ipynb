{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/06_pytorch_transfer_learning_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNqPNlYylluR"
      },
      "source": [
        "# 06. PyTorch Transfer Learning Exercises\n",
        "\n",
        "Welcome to the 06. PyTorch Transfer Learning exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
        "\n",
        "## Resources and solutions\n",
        "\n",
        "* These exercises/solutions are based on [section 06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
        "\n",
        "**Solutions:** \n",
        "\n",
        "Try to complete the code below *before* looking at these.\n",
        "\n",
        "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ueLolShyFqs).\n",
        "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/06_pytorch_transfer_learning_exercise_solutions.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwmoMhW8IqSu"
      },
      "source": [
        "## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels. \n",
        "* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n",
        "* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqtAWBUJgaF1",
        "outputId": "14cc75f3-e109-4e84-c941-2598df3557b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\miniconda\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O10_T_xSKJlf",
        "outputId": "fd30e756-e542-4b2b-d974-1ed38451fecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzg3TaSKLAh"
      },
      "source": [
        "### Get data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_CNQ4rKPmg",
        "outputId": "a1364d91-3afa-4401-94cb-94e4df837f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\Code\\pytorch-deep-learning\\data\\pizza_steak_sushi directory exists.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path.cwd().parent.parent / 'data'\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGaMWWaoKQlM"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VNIQNEQVKVXu"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njd5lHTcKW23",
        "outputId": "fbc224df-8243-4e7b-90cd-49adc000fd47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x1c359365fa0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x1c35931f5f0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciw2DiRHKaSE"
      },
      "source": [
        "### Get and prepare a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "6e25b4bb0d254191a793696a0f4f00ce",
            "37424313e66f474da42cfe1b512f09df",
            "58fd00f6a9114192a4fa757c1f669bff",
            "f115ea4b5fad4bb1910fca49ed3da8a1",
            "e8eba8e353e940ff9287929e41e4d656",
            "bc33539914a947ee89c271f10ea6a2bb",
            "6e03cb60fab94b7e92ce16c8178922dd",
            "5d464254c31d4516899643112fa0e958",
            "06df3ad4b7454556a43b6d61640b12f8",
            "0bdc7325c839439589a16c88876d6bd5",
            "873a483782894789bf0dee546a1b2d50"
          ]
        },
        "id": "snUuRXd8Kdk5",
        "outputId": "eac2a1e6-5607-437e-90b5-41639d17e5a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\miniconda\\envs\\torch\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "d:\\miniconda\\envs\\torch\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Setup the model with pretrained weights and send it to the target device \n",
        "model_0 = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
        "#model_0 # uncomment to output (it's very long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IbRhGvy_KeVL"
      },
      "outputs": [],
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model_0.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G1-6xV3ZKeSX"
      },
      "outputs": [],
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model_0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True), \n",
        "    torch.nn.Linear(in_features=1280, \n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQFaXX8CKePi"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "exxU79eaKeM6"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ae21171f17de45d895ab7a319dade609",
            "f9c60d9c0aed49faa993fd865fb09174",
            "755366e3f75e44c2b7a79bce78d77d11",
            "4a05e8d965124327a2329cf9e1eec984",
            "fe93ec079b384ac38a6f4d0e505431ff",
            "88dea77f1bcf44ffb69654515ee34f54",
            "2678a567b0414e1d9cfbfc2ecf5ffd30",
            "ce621be138a84f33b24c05b2d9cfd5f0",
            "1fa41d239a3a4845904434d057476a75",
            "f4827c6e36a1463fb0c82347f64230a2",
            "cea8f9c48bd8429998352a090173f537"
          ]
        },
        "id": "ComVkVtuKeKG",
        "outputId": "6d43205a-4e9f-4627-999a-40d07380cd58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:12<00:48, 12.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 1.0895 | train_acc: 0.4414 | test_loss: 0.9202 | test_acc: 0.5085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [00:24<00:36, 12.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2 | train_loss: 0.8682 | train_acc: 0.7734 | test_loss: 0.8022 | test_acc: 0.7434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [00:36<00:24, 12.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3 | train_loss: 0.7771 | train_acc: 0.7812 | test_loss: 0.7399 | test_acc: 0.7737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [00:48<00:12, 12.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4 | train_loss: 0.7248 | train_acc: 0.7422 | test_loss: 0.6471 | test_acc: 0.8864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [01:00<00:00, 12.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5 | train_loss: 0.6445 | train_acc: 0.7812 | test_loss: 0.6243 | test_acc: 0.8968\n",
            "[INFO] Total training time: 60.122 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer \n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "model_0_results = engine.train(model=model_0,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFS4lE_IKyE_"
      },
      "source": [
        "### Make predictions on the entire test dataset with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DwZuCluFu375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0])\n",
            "tensor([0.7350, 0.7350, 0.7350, 0.7350, 0.7350], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "y_pred_labels = []\n",
        "y_pred_probs = []\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    for batch , (X, y) in enumerate(test_dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        y_pred = model_0(X) # (32, 3)\n",
        "        y_prob = torch.softmax(y_pred, dim=1) # (32, 3)\n",
        "        y_pred_label = torch.argmax(y_prob, dim=1) # (32, )\n",
        "        \n",
        "        y_pred_labels.append(y_pred_label.cpu()) \n",
        "        y_pred_probs.append(y_prob[batch, y_pred_label])\n",
        "\n",
        "test_results = torch.cat(y_pred_labels)\n",
        "test_probs = torch.cat(y_pred_probs)\n",
        "print(test_results[:5])\n",
        "print(test_probs[:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb2bQ1b5K2WP"
      },
      "source": [
        "### Make a confusion matrix with the test preds and the truth labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I2jpYAcM07s"
      },
      "source": [
        "Need the following libraries to make a confusion matrix:\n",
        "* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n",
        "* mlxtend - http://rasbt.github.io/mlxtend/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKYZGWuK2P8",
        "outputId": "88c33b26-0b76-42d7-8a27-fb3073b1fc3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlxtend version: 0.24.0\n"
          ]
        }
      ],
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOYVew4xMxgI",
        "outputId": "d3b393b8-09c3-46f7-c799-2f91ee4d30e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.24.0\n"
          ]
        }
      ],
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend \n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_5LU9-5Xu7dP"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = torchmetrics.ConfusionMatrix(num_classes=3, task='multiclass')\n",
        "\n",
        "mat = confmat(test_results, torch.tensor(test_dataloader.dataset.targets))\n",
        "\n",
        "fig, ax = plot_confusion_matrix(mat.cpu().numpy(), class_names=test_dataloader.dataset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqlStPo-gbrF"
      },
      "source": [
        "## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
        "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
        "* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n",
        "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n",
        "\n",
        "You'll want to:\n",
        "* Create a DataFrame with sample, label, prediction, pred prob\n",
        "* Sort DataFrame by correct (does label == prediction)\n",
        "* Sort DataFrame by pred prob (descending)\n",
        "* Plot the top 5 \"most wrong\" image predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHtMeYHuvDwy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\26328\\AppData\\Local\\Temp\\ipykernel_11360\\2868751754.py:20: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  image_path = row[0]\n",
            "C:\\Users\\26328\\AppData\\Local\\Temp\\ipykernel_11360\\2868751754.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  true_label = row[1]\n",
            "C:\\Users\\26328\\AppData\\Local\\Temp\\ipykernel_11360\\2868751754.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_prob = row[2]\n",
            "C:\\Users\\26328\\AppData\\Local\\Temp\\ipykernel_11360\\2868751754.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pred_class = row[3]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "[Errno 2] No such file or directory: '('d:\\\\Code\\\\pytorch-deep-learning\\\\data\\\\pizza_steak_sushi\\\\test\\\\sushi\\\\1172255.jpg', 2)'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m pred_class = row[\u001b[32m3\u001b[39m]\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Plot the image and various details\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m img = \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get image as tensor\u001b[39;00m\n\u001b[32m     26\u001b[39m plt.figure()\n\u001b[32m     27\u001b[39m plt.imshow(img.permute(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m)) \u001b[38;5;66;03m# matplotlib likes images in [height, width, color_channels]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda\\envs\\torch\\Lib\\site-packages\\torchvision\\io\\image.py:336\u001b[39m, in \u001b[36mread_image\u001b[39m\u001b[34m(path, mode, apply_exif_orientation)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_tracing():\n\u001b[32m    335\u001b[39m     _log_api_usage_once(read_image)\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m data = \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m decode_image(data, mode, apply_exif_orientation=apply_exif_orientation)\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda\\envs\\torch\\Lib\\site-packages\\torchvision\\io\\image.py:64\u001b[39m, in \u001b[36mread_file\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_tracing():\n\u001b[32m     63\u001b[39m     _log_api_usage_once(read_file)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m data = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\miniconda\\envs\\torch\\Lib\\site-packages\\torch\\_ops.py:1255\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: [Errno 2] No such file or directory: '('d:\\\\Code\\\\pytorch-deep-learning\\\\data\\\\pizza_steak_sushi\\\\test\\\\sushi\\\\1172255.jpg', 2)'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pprint\n",
        "\n",
        "d = {'sample' : test_dataloader.dataset.samples, \n",
        "     'label' : test_dataloader.dataset.targets,\n",
        "     'prediction' : test_results.cpu().tolist(),\n",
        "     'prob' : test_probs.cpu().tolist()}\n",
        "\n",
        "df = pd.DataFrame(d)\n",
        "df['correct'] = [a == b for a, b in zip(d['prediction'], d['label'])]\n",
        "top_5_most_wrong = df.sort_values(by=[\"correct\", \"prob\"], ascending=[True, False]).head()\n",
        "top_5_most_wrong\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot the top 5 most wrong images\n",
        "for row in top_5_most_wrong.iterrows():\n",
        "  row = row[1]\n",
        "  image_path = row[0]\n",
        "  true_label = row[1]\n",
        "  pred_prob = row[2]\n",
        "  pred_class = row[3]\n",
        "  # Plot the image and various details\n",
        "  img = torchvision.io.read_image(str(image_path)) # get image as tensor\n",
        "  plt.figure()\n",
        "  plt.imshow(img.permute(1, 2, 0)) # matplotlib likes images in [height, width, color_channels]\n",
        "  plt.title(f\"True: {true_label} | Pred: {pred_class} | Prob: {pred_prob:.3f}\")\n",
        "  plt.axis(False);\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IvuTskxgjaw"
      },
      "source": [
        "## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n",
        "* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C16glgVFglmG"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of pizza/steak/sushi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clA_KmihVYyA"
      },
      "outputs": [],
      "source": [
        "# TODO: Get an image of not pizza/steak/sushi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzvi8GprgmJ0"
      },
      "source": [
        "## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n",
        "\n",
        "* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIKg53Jna-Rt"
      },
      "outputs": [],
      "source": [
        "# TODO: Recreate a new model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhGT9igPgoF5"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the model for 10 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oRrWPZTgoqL"
      },
      "source": [
        "## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n",
        "* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxyMMnUbgvw2"
      },
      "source": [
        "### Get 20% data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_fdu5m2eKT9",
        "outputId": "121c61f3-f505-4302-b3b9-8b8bae5b5e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Did not find data/pizza_steak_sushi_20_percent directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi 20% data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi_20_percent/train'),\n",
              " PosixPath('data/pizza_steak_sushi_20_percent/test'))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it... \n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / image_data_zip_path, \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / image_data_zip_path)\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir_20_percent = image_path / \"train\"\n",
        "test_dir_20_percent = image_path / \"test\"\n",
        "\n",
        "train_dir_20_percent, test_dir_20_percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQj7eFdSe4Fv"
      },
      "source": [
        "### Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEG_k785e7Jw"
      },
      "outputs": [],
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82x7LnQJe7H5",
        "outputId": "342fd4e7-0656-495a-aee0-0d23be130438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f5ede28e390>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f5ede28e210>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "                                                                                                     test_dir=test_dir_20_percent,\n",
        "                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                                                     batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qROl77sKfIOd"
      },
      "source": [
        "### Get a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHWNZ6yDvpR8"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqffJfOIfp3T"
      },
      "source": [
        "### Train a model with 20% of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXpYOYeTvp7a"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibj4UPjRgvly"
      },
      "source": [
        "## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n",
        "* You'll have to change the size of the classifier layer to suit our problem.\n",
        "* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n",
        "  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FQ8tL7El7eO"
      },
      "outputs": [],
      "source": [
        "# TODO "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNXgsMoZLpp/LR5qPnNG65Z",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "06_pytorch_transfer_learning_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06df3ad4b7454556a43b6d61640b12f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdc7325c839439589a16c88876d6bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa41d239a3a4845904434d057476a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2678a567b0414e1d9cfbfc2ecf5ffd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37424313e66f474da42cfe1b512f09df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc33539914a947ee89c271f10ea6a2bb",
            "placeholder": "​",
            "style": "IPY_MODEL_6e03cb60fab94b7e92ce16c8178922dd",
            "value": "100%"
          }
        },
        "4a05e8d965124327a2329cf9e1eec984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4827c6e36a1463fb0c82347f64230a2",
            "placeholder": "​",
            "style": "IPY_MODEL_cea8f9c48bd8429998352a090173f537",
            "value": " 5/5 [00:31&lt;00:00,  5.81s/it]"
          }
        },
        "58fd00f6a9114192a4fa757c1f669bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d464254c31d4516899643112fa0e958",
            "max": 21444401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06df3ad4b7454556a43b6d61640b12f8",
            "value": 21444401
          }
        },
        "5d464254c31d4516899643112fa0e958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e03cb60fab94b7e92ce16c8178922dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e25b4bb0d254191a793696a0f4f00ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37424313e66f474da42cfe1b512f09df",
              "IPY_MODEL_58fd00f6a9114192a4fa757c1f669bff",
              "IPY_MODEL_f115ea4b5fad4bb1910fca49ed3da8a1"
            ],
            "layout": "IPY_MODEL_e8eba8e353e940ff9287929e41e4d656"
          }
        },
        "755366e3f75e44c2b7a79bce78d77d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce621be138a84f33b24c05b2d9cfd5f0",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa41d239a3a4845904434d057476a75",
            "value": 5
          }
        },
        "873a483782894789bf0dee546a1b2d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88dea77f1bcf44ffb69654515ee34f54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae21171f17de45d895ab7a319dade609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9c60d9c0aed49faa993fd865fb09174",
              "IPY_MODEL_755366e3f75e44c2b7a79bce78d77d11",
              "IPY_MODEL_4a05e8d965124327a2329cf9e1eec984"
            ],
            "layout": "IPY_MODEL_fe93ec079b384ac38a6f4d0e505431ff"
          }
        },
        "bc33539914a947ee89c271f10ea6a2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce621be138a84f33b24c05b2d9cfd5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea8f9c48bd8429998352a090173f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8eba8e353e940ff9287929e41e4d656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f115ea4b5fad4bb1910fca49ed3da8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc7325c839439589a16c88876d6bd5",
            "placeholder": "​",
            "style": "IPY_MODEL_873a483782894789bf0dee546a1b2d50",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 61.8MB/s]"
          }
        },
        "f4827c6e36a1463fb0c82347f64230a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9c60d9c0aed49faa993fd865fb09174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88dea77f1bcf44ffb69654515ee34f54",
            "placeholder": "​",
            "style": "IPY_MODEL_2678a567b0414e1d9cfbfc2ecf5ffd30",
            "value": "100%"
          }
        },
        "fe93ec079b384ac38a6f4d0e505431ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
